{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Ukejr2ZaIWlB"
      },
      "id": "Ukejr2ZaIWlB",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_binary_labeled"
      ],
      "metadata": {
        "id": "4gcg07KEIaIK"
      },
      "id": "4gcg07KEIaIK",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['label']).values\n",
        "y = df['label'].values"
      ],
      "metadata": {
        "id": "ORwpkfgmIiqw"
      },
      "id": "ORwpkfgmIiqw",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)\n"
      ],
      "metadata": {
        "id": "dVrkK9AGIkr5"
      },
      "id": "dVrkK9AGIkr5",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
        "print(f\"Validation set shape: {X_val_scaled.shape}\")\n",
        "print(f\"Test set shape: {X_test_scaled.shape}\")\n",
        "print(f\"Class distribution - Training: {np.bincount(y_train.astype(int))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGfT_RJxIpPO",
        "outputId": "9f15854c-b043-458f-812c-370bed90179d"
      },
      "id": "YGfT_RJxIpPO",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (906, 15)\n",
            "Validation set shape: (302, 15)\n",
            "Test set shape: (302, 15)\n",
            "Class distribution - Training: [262 644]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    # Reshape input for CNN (treating features as 1D sequence)\n",
        "    layers.Reshape((X_train_scaled.shape[1], 1), input_shape=(X_train_scaled.shape[1],)),\n",
        "\n",
        "    # First convolutional block\n",
        "    layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    # Second convolutional block\n",
        "    layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling1D(pool_size=2),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    # Third convolutional block\n",
        "    layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.GlobalMaxPooling1D(),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    # Dense layers\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    # Output layer for binary classification\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7siZv40JRps",
        "outputId": "cd34caa1-f92a-477b-b6a7-994710ce4bb0"
      },
      "id": "U7siZv40JRps",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', 'precision', 'recall']\n",
        ")"
      ],
      "metadata": {
        "id": "_lqQdUZUJaS0"
      },
      "id": "_lqQdUZUJaS0",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "m8XkSR64Jcqb",
        "outputId": "6c87da10-207e-4db1-b5ce-fe7f8274c44f"
      },
      "id": "m8XkSR64Jcqb",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m6,208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,561\u001b[0m (166.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,561</span> (166.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,985\u001b[0m (164.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,985</span> (164.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m576\u001b[0m (2.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> (2.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0.0001\n",
        ")"
      ],
      "metadata": {
        "id": "H97w27ZSJfbc"
      },
      "id": "H97w27ZSJfbc",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    epochs=40,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfBT5DipJjqx",
        "outputId": "5e48e0d7-550e-4936-e2dd-f5e5588c1e94"
      },
      "id": "OfBT5DipJjqx",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.4428 - loss: 1.1309 - precision: 0.7170 - recall: 0.3300 - val_accuracy: 0.7682 - val_loss: 0.6110 - val_precision: 0.8000 - val_recall: 0.8972 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7428 - loss: 0.6262 - precision: 0.8808 - recall: 0.7332 - val_accuracy: 0.7715 - val_loss: 0.5152 - val_precision: 0.7599 - val_recall: 0.9907 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7695 - loss: 0.5079 - precision: 0.8596 - recall: 0.8096 - val_accuracy: 0.7715 - val_loss: 0.4937 - val_precision: 0.7599 - val_recall: 0.9907 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7909 - loss: 0.5047 - precision: 0.8353 - recall: 0.8623 - val_accuracy: 0.7715 - val_loss: 0.4869 - val_precision: 0.7599 - val_recall: 0.9907 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7720 - loss: 0.4656 - precision: 0.8373 - recall: 0.8425 - val_accuracy: 0.7748 - val_loss: 0.4862 - val_precision: 0.7626 - val_recall: 0.9907 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8044 - loss: 0.4542 - precision: 0.8444 - recall: 0.8865 - val_accuracy: 0.7748 - val_loss: 0.4832 - val_precision: 0.7645 - val_recall: 0.9860 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8403 - loss: 0.4061 - precision: 0.8835 - recall: 0.8957 - val_accuracy: 0.7914 - val_loss: 0.4871 - val_precision: 0.7786 - val_recall: 0.9860 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7867 - loss: 0.4772 - precision: 0.8275 - recall: 0.8776 - val_accuracy: 0.8013 - val_loss: 0.4429 - val_precision: 0.7917 - val_recall: 0.9766 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8059 - loss: 0.4264 - precision: 0.8381 - recall: 0.8961 - val_accuracy: 0.8179 - val_loss: 0.4318 - val_precision: 0.8093 - val_recall: 0.9720 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8194 - loss: 0.4570 - precision: 0.8481 - recall: 0.8970 - val_accuracy: 0.8278 - val_loss: 0.4130 - val_precision: 0.8240 - val_recall: 0.9626 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8211 - loss: 0.4320 - precision: 0.8633 - recall: 0.8885 - val_accuracy: 0.8311 - val_loss: 0.3924 - val_precision: 0.8300 - val_recall: 0.9579 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8350 - loss: 0.4261 - precision: 0.8555 - recall: 0.9136 - val_accuracy: 0.8411 - val_loss: 0.3740 - val_precision: 0.8430 - val_recall: 0.9533 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8218 - loss: 0.3997 - precision: 0.8758 - recall: 0.8780 - val_accuracy: 0.8377 - val_loss: 0.3723 - val_precision: 0.8452 - val_recall: 0.9439 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8097 - loss: 0.4623 - precision: 0.8297 - recall: 0.9105 - val_accuracy: 0.8510 - val_loss: 0.3561 - val_precision: 0.8506 - val_recall: 0.9579 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8327 - loss: 0.4141 - precision: 0.8626 - recall: 0.9126 - val_accuracy: 0.8576 - val_loss: 0.3289 - val_precision: 0.8608 - val_recall: 0.9533 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8527 - loss: 0.3779 - precision: 0.8796 - recall: 0.9128 - val_accuracy: 0.8709 - val_loss: 0.3171 - val_precision: 0.8755 - val_recall: 0.9533 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8361 - loss: 0.3868 - precision: 0.8853 - recall: 0.8872 - val_accuracy: 0.8675 - val_loss: 0.3171 - val_precision: 0.8686 - val_recall: 0.9579 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8505 - loss: 0.3432 - precision: 0.8836 - recall: 0.9092 - val_accuracy: 0.8775 - val_loss: 0.3095 - val_precision: 0.8734 - val_recall: 0.9673 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8649 - loss: 0.3455 - precision: 0.8993 - recall: 0.9195 - val_accuracy: 0.8709 - val_loss: 0.3046 - val_precision: 0.8661 - val_recall: 0.9673 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8604 - loss: 0.3345 - precision: 0.9052 - recall: 0.9005 - val_accuracy: 0.8742 - val_loss: 0.3056 - val_precision: 0.8729 - val_recall: 0.9626 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8579 - loss: 0.3398 - precision: 0.9029 - recall: 0.9028 - val_accuracy: 0.8709 - val_loss: 0.2995 - val_precision: 0.8755 - val_recall: 0.9533 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8655 - loss: 0.3428 - precision: 0.9027 - recall: 0.9136 - val_accuracy: 0.8775 - val_loss: 0.2971 - val_precision: 0.8734 - val_recall: 0.9673 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8777 - loss: 0.3318 - precision: 0.8963 - recall: 0.9389 - val_accuracy: 0.8742 - val_loss: 0.3012 - val_precision: 0.8636 - val_recall: 0.9766 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8464 - loss: 0.3333 - precision: 0.8799 - recall: 0.9106 - val_accuracy: 0.8841 - val_loss: 0.2955 - val_precision: 0.8745 - val_recall: 0.9766 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8739 - loss: 0.3067 - precision: 0.8864 - recall: 0.9375 - val_accuracy: 0.8742 - val_loss: 0.3109 - val_precision: 0.8636 - val_recall: 0.9766 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8366 - loss: 0.3680 - precision: 0.8760 - recall: 0.9033 - val_accuracy: 0.8841 - val_loss: 0.3103 - val_precision: 0.8683 - val_recall: 0.9860 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8716 - loss: 0.3098 - precision: 0.8937 - recall: 0.9332 - val_accuracy: 0.8742 - val_loss: 0.3086 - val_precision: 0.8636 - val_recall: 0.9766 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8706 - loss: 0.3091 - precision: 0.8900 - recall: 0.9327 - val_accuracy: 0.8742 - val_loss: 0.3046 - val_precision: 0.8729 - val_recall: 0.9626 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8725 - loss: 0.3336 - precision: 0.9001 - recall: 0.9262 - val_accuracy: 0.8841 - val_loss: 0.2977 - val_precision: 0.8809 - val_recall: 0.9673 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8917 - loss: 0.2770 - precision: 0.9199 - recall: 0.9328 - val_accuracy: 0.8841 - val_loss: 0.2968 - val_precision: 0.8809 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8564 - loss: 0.3509 - precision: 0.8789 - recall: 0.9162 - val_accuracy: 0.8907 - val_loss: 0.2940 - val_precision: 0.8884 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8796 - loss: 0.2881 - precision: 0.9077 - recall: 0.9282 - val_accuracy: 0.8907 - val_loss: 0.2941 - val_precision: 0.8884 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8735 - loss: 0.3321 - precision: 0.8809 - recall: 0.9430 - val_accuracy: 0.8874 - val_loss: 0.2916 - val_precision: 0.8879 - val_recall: 0.9626 - learning_rate: 2.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8675 - loss: 0.3546 - precision: 0.8820 - recall: 0.9359 - val_accuracy: 0.8874 - val_loss: 0.2881 - val_precision: 0.8879 - val_recall: 0.9626 - learning_rate: 2.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8823 - loss: 0.2998 - precision: 0.9067 - recall: 0.9284 - val_accuracy: 0.8940 - val_loss: 0.2880 - val_precision: 0.8922 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8707 - loss: 0.3063 - precision: 0.9140 - recall: 0.9099 - val_accuracy: 0.8940 - val_loss: 0.2886 - val_precision: 0.8889 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8514 - loss: 0.3646 - precision: 0.8785 - recall: 0.9226 - val_accuracy: 0.8940 - val_loss: 0.2841 - val_precision: 0.8922 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8765 - loss: 0.3103 - precision: 0.8854 - recall: 0.9452 - val_accuracy: 0.8907 - val_loss: 0.2864 - val_precision: 0.8851 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8759 - loss: 0.3272 - precision: 0.8978 - recall: 0.9278 - val_accuracy: 0.8907 - val_loss: 0.2842 - val_precision: 0.8851 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8797 - loss: 0.3145 - precision: 0.8983 - recall: 0.9373 - val_accuracy: 0.8907 - val_loss: 0.2848 - val_precision: 0.8851 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8802 - loss: 0.3004 - precision: 0.8931 - recall: 0.9402 - val_accuracy: 0.8907 - val_loss: 0.2816 - val_precision: 0.8851 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8602 - loss: 0.3315 - precision: 0.8850 - recall: 0.9205 - val_accuracy: 0.8907 - val_loss: 0.2822 - val_precision: 0.8851 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8818 - loss: 0.3052 - precision: 0.9017 - recall: 0.9335 - val_accuracy: 0.8940 - val_loss: 0.2786 - val_precision: 0.8889 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8598 - loss: 0.3297 - precision: 0.8763 - recall: 0.9344 - val_accuracy: 0.8940 - val_loss: 0.2770 - val_precision: 0.8922 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8593 - loss: 0.3130 - precision: 0.8958 - recall: 0.9138 - val_accuracy: 0.8907 - val_loss: 0.2774 - val_precision: 0.8851 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8801 - loss: 0.3086 - precision: 0.9167 - recall: 0.9201 - val_accuracy: 0.8907 - val_loss: 0.2781 - val_precision: 0.8851 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8520 - loss: 0.3238 - precision: 0.8632 - recall: 0.9349 - val_accuracy: 0.8940 - val_loss: 0.2759 - val_precision: 0.8922 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8725 - loss: 0.3134 - precision: 0.8908 - recall: 0.9332 - val_accuracy: 0.8974 - val_loss: 0.2731 - val_precision: 0.8961 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8693 - loss: 0.3235 - precision: 0.8982 - recall: 0.9244 - val_accuracy: 0.8974 - val_loss: 0.2736 - val_precision: 0.8961 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8689 - loss: 0.3461 - precision: 0.8976 - recall: 0.9243 - val_accuracy: 0.9007 - val_loss: 0.2757 - val_precision: 0.8966 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8892 - loss: 0.3017 - precision: 0.8988 - recall: 0.9518 - val_accuracy: 0.8974 - val_loss: 0.2745 - val_precision: 0.8927 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8734 - loss: 0.3354 - precision: 0.8938 - recall: 0.9321 - val_accuracy: 0.8974 - val_loss: 0.2713 - val_precision: 0.8961 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8607 - loss: 0.3148 - precision: 0.8950 - recall: 0.9144 - val_accuracy: 0.9040 - val_loss: 0.2702 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8940 - loss: 0.2899 - precision: 0.9181 - recall: 0.9392 - val_accuracy: 0.8974 - val_loss: 0.2705 - val_precision: 0.8961 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8831 - loss: 0.2969 - precision: 0.9089 - recall: 0.9289 - val_accuracy: 0.8974 - val_loss: 0.2706 - val_precision: 0.8961 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8873 - loss: 0.2994 - precision: 0.9055 - recall: 0.9376 - val_accuracy: 0.8974 - val_loss: 0.2702 - val_precision: 0.8961 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8861 - loss: 0.2823 - precision: 0.9108 - recall: 0.9334 - val_accuracy: 0.8974 - val_loss: 0.2694 - val_precision: 0.8961 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8831 - loss: 0.2800 - precision: 0.8922 - recall: 0.9486 - val_accuracy: 0.8974 - val_loss: 0.2690 - val_precision: 0.8961 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8844 - loss: 0.2749 - precision: 0.9037 - recall: 0.9333 - val_accuracy: 0.8974 - val_loss: 0.2710 - val_precision: 0.8961 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8762 - loss: 0.3125 - precision: 0.9055 - recall: 0.9272 - val_accuracy: 0.8940 - val_loss: 0.2715 - val_precision: 0.8922 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8834 - loss: 0.2890 - precision: 0.8933 - recall: 0.9442 - val_accuracy: 0.9040 - val_loss: 0.2683 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8824 - loss: 0.2967 - precision: 0.9036 - recall: 0.9389 - val_accuracy: 0.8974 - val_loss: 0.2686 - val_precision: 0.8927 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8832 - loss: 0.3102 - precision: 0.8872 - recall: 0.9510 - val_accuracy: 0.9007 - val_loss: 0.2658 - val_precision: 0.9000 - val_recall: 0.9673 - learning_rate: 2.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8845 - loss: 0.3219 - precision: 0.9098 - recall: 0.9314 - val_accuracy: 0.8974 - val_loss: 0.2698 - val_precision: 0.8894 - val_recall: 0.9766 - learning_rate: 2.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8601 - loss: 0.3404 - precision: 0.8840 - recall: 0.9214 - val_accuracy: 0.9040 - val_loss: 0.2679 - val_precision: 0.8970 - val_recall: 0.9766 - learning_rate: 2.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8913 - loss: 0.2882 - precision: 0.9205 - recall: 0.9296 - val_accuracy: 0.9040 - val_loss: 0.2685 - val_precision: 0.8970 - val_recall: 0.9766 - learning_rate: 2.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8686 - loss: 0.2986 - precision: 0.8932 - recall: 0.9267 - val_accuracy: 0.9040 - val_loss: 0.2687 - val_precision: 0.8970 - val_recall: 0.9766 - learning_rate: 2.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8697 - loss: 0.3036 - precision: 0.9024 - recall: 0.9164 - val_accuracy: 0.9040 - val_loss: 0.2665 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 2.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8753 - loss: 0.2993 - precision: 0.8957 - recall: 0.9288 - val_accuracy: 0.9007 - val_loss: 0.2640 - val_precision: 0.9000 - val_recall: 0.9673 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8702 - loss: 0.3280 - precision: 0.9050 - recall: 0.9181 - val_accuracy: 0.9007 - val_loss: 0.2647 - val_precision: 0.9000 - val_recall: 0.9673 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9009 - loss: 0.2593 - precision: 0.9139 - recall: 0.9503 - val_accuracy: 0.9007 - val_loss: 0.2650 - val_precision: 0.9000 - val_recall: 0.9673 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8933 - loss: 0.2683 - precision: 0.9172 - recall: 0.9386 - val_accuracy: 0.9007 - val_loss: 0.2640 - val_precision: 0.9000 - val_recall: 0.9673 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8944 - loss: 0.2668 - precision: 0.9075 - recall: 0.9489 - val_accuracy: 0.9040 - val_loss: 0.2616 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8782 - loss: 0.2782 - precision: 0.8990 - recall: 0.9327 - val_accuracy: 0.9007 - val_loss: 0.2601 - val_precision: 0.9000 - val_recall: 0.9673 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8922 - loss: 0.2745 - precision: 0.9071 - recall: 0.9424 - val_accuracy: 0.9040 - val_loss: 0.2600 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8664 - loss: 0.3142 - precision: 0.8980 - recall: 0.9183 - val_accuracy: 0.9040 - val_loss: 0.2572 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8749 - loss: 0.3148 - precision: 0.9025 - recall: 0.9251 - val_accuracy: 0.9040 - val_loss: 0.2567 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9052 - loss: 0.2929 - precision: 0.9278 - recall: 0.9416 - val_accuracy: 0.9040 - val_loss: 0.2589 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9061 - loss: 0.2621 - precision: 0.9106 - recall: 0.9630 - val_accuracy: 0.9040 - val_loss: 0.2586 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8564 - loss: 0.3126 - precision: 0.8754 - recall: 0.9277 - val_accuracy: 0.9040 - val_loss: 0.2578 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8833 - loss: 0.2788 - precision: 0.9068 - recall: 0.9356 - val_accuracy: 0.9073 - val_loss: 0.2594 - val_precision: 0.9009 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8975 - loss: 0.2777 - precision: 0.9080 - recall: 0.9485 - val_accuracy: 0.9073 - val_loss: 0.2589 - val_precision: 0.9009 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8581 - loss: 0.3023 - precision: 0.8777 - recall: 0.9237 - val_accuracy: 0.9073 - val_loss: 0.2549 - val_precision: 0.9009 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9071 - loss: 0.2605 - precision: 0.9105 - recall: 0.9617 - val_accuracy: 0.9073 - val_loss: 0.2564 - val_precision: 0.9009 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8779 - loss: 0.3175 - precision: 0.9112 - recall: 0.9238 - val_accuracy: 0.9007 - val_loss: 0.2598 - val_precision: 0.8932 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8700 - loss: 0.3031 - precision: 0.8831 - recall: 0.9370 - val_accuracy: 0.9073 - val_loss: 0.2574 - val_precision: 0.9009 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9027 - loss: 0.2632 - precision: 0.9180 - recall: 0.9492 - val_accuracy: 0.9040 - val_loss: 0.2586 - val_precision: 0.8970 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9082 - loss: 0.2696 - precision: 0.9254 - recall: 0.9469 - val_accuracy: 0.9040 - val_loss: 0.2582 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8752 - loss: 0.3057 - precision: 0.8965 - recall: 0.9300 - val_accuracy: 0.9040 - val_loss: 0.2566 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.2759 - precision: 0.9208 - recall: 0.9377 - val_accuracy: 0.9040 - val_loss: 0.2560 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8782 - loss: 0.2873 - precision: 0.8883 - recall: 0.9443 - val_accuracy: 0.9040 - val_loss: 0.2541 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8915 - loss: 0.2909 - precision: 0.9030 - recall: 0.9482 - val_accuracy: 0.9040 - val_loss: 0.2537 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8815 - loss: 0.3077 - precision: 0.9100 - recall: 0.9294 - val_accuracy: 0.9040 - val_loss: 0.2543 - val_precision: 0.9004 - val_recall: 0.9720 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8923 - loss: 0.2731 - precision: 0.9186 - recall: 0.9353 - val_accuracy: 0.9040 - val_loss: 0.2560 - val_precision: 0.8970 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8827 - loss: 0.2706 - precision: 0.9083 - recall: 0.9280 - val_accuracy: 0.9040 - val_loss: 0.2566 - val_precision: 0.8970 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9007 - loss: 0.2509 - precision: 0.9141 - recall: 0.9486 - val_accuracy: 0.9073 - val_loss: 0.2557 - val_precision: 0.8974 - val_recall: 0.9813 - learning_rate: 1.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8898 - loss: 0.3043 - precision: 0.9137 - recall: 0.9343 - val_accuracy: 0.9040 - val_loss: 0.2568 - val_precision: 0.8970 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8810 - loss: 0.2764 - precision: 0.9030 - recall: 0.9322 - val_accuracy: 0.9073 - val_loss: 0.2544 - val_precision: 0.9009 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9110 - loss: 0.2557 - precision: 0.9280 - recall: 0.9482 - val_accuracy: 0.9040 - val_loss: 0.2560 - val_precision: 0.8970 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8995 - loss: 0.2583 - precision: 0.9105 - recall: 0.9542 - val_accuracy: 0.9040 - val_loss: 0.2554 - val_precision: 0.8970 - val_recall: 0.9766 - learning_rate: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1-Score: {2 * (test_precision * test_recall) / (test_precision + test_recall):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSdtVggbKsJ5",
        "outputId": "771f198e-ce3e-4411-de29-5cde8a731f5e"
      },
      "id": "lSdtVggbKsJ5",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Results:\n",
            "Test Accuracy: 0.9073\n",
            "Test Precision: 0.9043\n",
            "Test Recall: 0.9720\n",
            "Test F1-Score: 0.9369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = model.predict(X_test_scaled)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-qAOIBWKvEv",
        "outputId": "7d987920-791f-41e6-b94a-59d1de29ff22"
      },
      "id": "g-qAOIBWKvEv",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/Users/mansahaj/Downloads/exoplanet_cnn_model.h5')\n",
        "print(\"\\nModel saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwsn-eoXKxQD",
        "outputId": "9c27a7cb-96a6-4041-c2b1-c49a1ce38dcc"
      },
      "id": "vwsn-eoXKxQD",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model saved successfully!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}